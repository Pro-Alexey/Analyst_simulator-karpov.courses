{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6b153e-74b6-4692-a085-59cac62f398a",
   "metadata": {},
   "source": [
    "# Построение ETL-пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47a01b-a52c-4672-b1c6-c6d02e483918",
   "metadata": {},
   "source": [
    "В данном задании мы пишем код для построения нашего отчёта через Airflow и дальше отправляет этот отчёт в ClickHouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70c434-afd1-4692-94aa-bedd07385d44",
   "metadata": {},
   "source": [
    "#### Порядок действий:\n",
    "1. Параллельно будем обрабатывать две таблицы. В feed_actions для каждого юзера посчитаем число просмотров и лайков контента. В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. Каждая выгрузка должна быть в отдельном таске.\n",
    "2. Далее объединяем две таблицы в одну.\n",
    "3. Для этой таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез.\n",
    "4. И финальные данные со всеми метриками записываем в отдельную таблицу в ClickHouse.\n",
    "5. Каждый день таблица должна дополняться новыми данными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1432c8-913f-4b13-a81b-08219392f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "import pandahouse\n",
    "import seaborn as sns\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context\n",
    "\n",
    "\n",
    "# бд от куда загрузить исходные данные\n",
    "connection = {\n",
    "    'host': 'https://clickhouse.lab.karpov.courses',\n",
    "    'password': 'dpo_python_2020',\n",
    "    'user': 'student',\n",
    "    'database': 'simulator_20220320'\n",
    "}\n",
    "\n",
    "# бд куда выгрузить данные\n",
    "connection_upload = {\n",
    "                'host': 'https://clickhouse.lab.karpov.courses',\n",
    "                'password': '656e2b0c9c',\n",
    "                'user': 'student-rw',\n",
    "                'database': 'test'\n",
    "}\n",
    "\n",
    "def request(q):\n",
    "    return pandahouse.read_clickhouse(q, connection=connection)\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "    'owner': 'a.pronin',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2022, 6, 14),\n",
    "}\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 0 * * *'\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup = False)\n",
    "def dag_etl_pronin():\n",
    "    \n",
    "    @task()\n",
    "    def exatract_feed():\n",
    "        return request('''SELECT \n",
    "                               toDate(time) as event_date, user_id,\n",
    "                               countIf(action = 'like') as likes,\n",
    "                               countIf(action = 'view') as views,\n",
    "                               gender, age, os\n",
    "                          FROM simulator_20220520.feed_actions \n",
    "                          WHERE toDate(time) = today() - 1\n",
    "                          GROUP BY event_date, user_id, gender, age, os''')\n",
    "    @task()\n",
    "    def exatract_message():\n",
    "        return request('''SELECT event_date, user_id, gender, os, age, messages_sent, users_sent, messages_received, users_received\n",
    "                            FROM\n",
    "                            (SELECT  \n",
    "                            toDate(time) as event_date, user_id, \n",
    "                            count(reciever_id) as messages_sent,\n",
    "                            count(distinct reciever_id) as users_sent,\n",
    "                            gender, age, os\n",
    "                            FROM simulator_20220520.message_actions \n",
    "                            WHERE toDate(time) = today() - 1\n",
    "                            GROUP BY event_date, user_id, gender, age, os) t1\n",
    "\n",
    "                            join\n",
    "\n",
    "                            (SELECT  \n",
    "                            toDate(time) as event_date, reciever_id, \n",
    "                            count(user_id) as messages_received,\n",
    "                            count(distinct user_id) as users_received\n",
    "                            FROM simulator_20220520.message_actions \n",
    "                            WHERE toDate(time) = today() - 1\n",
    "                            GROUP BY event_date, reciever_id) t2\n",
    "\n",
    "                            ON t1.user_id = t2.reciever_id AND t1.event_date= t2.event_date''')\n",
    "    \n",
    "    #От скольких пользователей получили сообщения - users_received\n",
    "    #Скольким пользователям отправили сообщение - users_sent\n",
    "    #Число полученных сообщений - messages_received\n",
    "    #Число отправленных сообщений - messages_sent\n",
    "\n",
    "    \n",
    "    @task()\n",
    "    def merge_request(q_feed, q_message):\n",
    "        df = q_feed.merge(q_message, on = ['event_date', 'user_id', 'gender','age','os'], how='outer')\n",
    "        \n",
    "        df['gender'] = df['gender'].apply(lambda x: 'male' if x == 1 else 'femail')\n",
    "        \n",
    "        def value_age(age):\n",
    "            if age < 18:\n",
    "                return '0-17'\n",
    "            elif 17 < age < 25:\n",
    "                return '18-24'\n",
    "            elif 24 < age < 35:\n",
    "                return '25-34'\n",
    "            elif 34 < age < 45:\n",
    "                return '35-44'\n",
    "            else:\n",
    "                return '45+'\n",
    "            \n",
    "        df['age'] = df['age'].apply(value_age)\n",
    "        \n",
    "        df = df[['event_date', 'gender', 'os', 'age', 'likes', 'views', 'messages_sent', 'users_sent', 'messages_received', 'users_received']]\n",
    "        \n",
    "        return df\n",
    "            \n",
    "    @task()\n",
    "    def metrics_os(df):\n",
    "        df['metrics'] = 'os: ' + df['os']\n",
    "        os_df = df.groupby(['event_date', 'metrics'])['likes','views','messages_received','messages_sent','users_received','users_sent'].sum().sort_index().reset_index()\n",
    "        return os_df\n",
    "    @task()\n",
    "    def metrics_age(df):\n",
    "        df['metrics'] = 'age: ' + df['age']\n",
    "        age_df = df.groupby(['event_date', 'metrics'])['likes','views','messages_received','messages_sent','users_received','users_sent'].sum().sort_index().reset_index()\n",
    "        return age_df\n",
    "    @task()\n",
    "    def metrics_gender(df):\n",
    "        df['metrics'] = 'gender: ' + df['gender']\n",
    "        gender_df = df.groupby(['event_date', 'metrics'])['likes','views','messages_received','messages_sent','users_received','users_sent'].sum().sort_index().reset_index()\n",
    "        return gender_df\n",
    "    \n",
    "    @task()\n",
    "    def concat_metrics(os_df, age_df, gender_df):\n",
    "        final_df = pd.concat([gender_df, os_df, age_df])\n",
    "        return final_df\n",
    "    \n",
    "    @task()\n",
    "    def load(final_df):\n",
    "        q_final = '''CREATE TABLE IF NOT EXISTS test.pronin_v1\n",
    "                (   event_date Date,\n",
    "                    metrics String,\n",
    "                    likes UInt64,\n",
    "                    views UInt64,\n",
    "                    messages_received UInt64,\n",
    "                    messages_sent UInt64,\n",
    "                    users_received UInt64,\n",
    "                    users_sent UInt64\n",
    "                ) ENGINE = MergeTree'''\n",
    "\n",
    "        pandahouse.execute(query=q_final, connection=connection_upload)\n",
    "\n",
    "        pandahouse.to_clickhouse(final_df, 'pronin_v1', connection=connection_upload, index=False)\n",
    "        \n",
    "    q_feed = exatract_feed()\n",
    "    q_message = exatract_message()\n",
    "    df = merge_request(q_feed, q_message)\n",
    "\n",
    "    os_df = metrics_os(df)\n",
    "    age_df = metrics_age(df)\n",
    "    gender_df = metrics_gender(df)\n",
    "    \n",
    "    final_df = concat_metrics(os_df, age_df, gender_df)\n",
    "    \n",
    "    load(final_df)\n",
    "\n",
    "dag_etl_pronin = dag_etl_pronin()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be758c7-2b34-4996-ba0e-1effa0fc8404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
